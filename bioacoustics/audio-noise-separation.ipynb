{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4582bc7b",
   "metadata": {},
   "source": [
    "# Audio Noise Separation\n",
    "This is part of audio data preprocessing. In this notebook, we will split the audio files into signal part where bird sounds are audible and noise part where there are no bird sounds (background noise may be present in this part). The separation of the audio file into signal and noise parts is done as described in **Sprengel, E., Jaggi, M., Kilcher, Y., & Hofmann, T. (2016). Audio based bird species identification using deep learning techniques**.\n",
    "\n",
    "## Signal extraction\n",
    "To separate an audio file into a signal and a noise part, we first compute the spectrogram of the whole file. We then normalize the spectrogram by dividing every pixel with the maximum pixel value. To select the parts that correspond to the signal part, we pick all the pixels that are three times bigger than the row median and three times bigger than the column median. Ideally, this should give us the parts that correspond to a signal since high amplitude to a bird audio. The selected pixels are then set to 1 and everything else to 0. A binary erosion and dilation filter is then applied to get rid of noise and join the segments. A 4 by 4 filter was used in this case.\n",
    "\n",
    "We then proceed to create an indicator vector with as many elements as there are columns in the spectrogram. The i-th element in this vector is set to 1 if the i-th column contains at least one 1, otherwise it is set to 0. The indicator vector is smoothened by applying two more binary 4 by 1 dilation filters. The indicator vector is then scaled to the length of the original audio file and used as a mask to extract the signal part. The parts obtained are joined to form one signal audio and saved as a signal file.\n",
    "\n",
    "## Noise extraction\n",
    "For noise part extraction, we follow the same procedure used above but in this case we select the pixels that are 2.5 times bigger than the row and column median. We then follow the procedure as described above but the results are inverted in the very end. The parts obtained are joined to form one noise audio and saved as a noise file. The use of the different thresholds (3 and 2.5) when selecting the signal and noise parts provides a safety margin in the selection process and it means some columns may not correspond to either sound or noise parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_dilation, binary_erosion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c354596",
   "metadata": {},
   "source": [
    "### Loading parameters needed to compute spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get parameters from configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('parameters.ini')\n",
    "\n",
    "win_len_ms = int(config['audio']['win_len_ms'])\n",
    "overlap = float(config['audio']['overlap'])\n",
    "sampling_rate = int(config['audio']['sampling_rate'])\n",
    "\n",
    "\n",
    "# Derive audio processing values\n",
    "win_len = int((win_len_ms * sampling_rate) / 1000)\n",
    "hop_len = int(win_len * (1 - overlap))\n",
    "nfft = int(2 ** np.ceil(np.log2(win_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b24eb6",
   "metadata": {},
   "source": [
    "### Load and play a sample file\n",
    "Let's load a sample audio file that we will use for the entire of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c741949",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './sample_data'\n",
    "file = os.path.join(path, os.listdir(path)[0])\n",
    "y, _ = librosa.load(file, sr=sampling_rate)\n",
    "IPython.display.Audio(y, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f327556",
   "metadata": {},
   "source": [
    "### Compute and normalize a spectrogram\n",
    "Now let us compute the spectrogram of the loaded file, normalize it and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "specgram = np.abs(librosa.stft(y, \n",
    "                    n_fft=nfft, \n",
    "                    hop_length=hop_len))\n",
    "normalized_specgram = specgram / (specgram.max() + 1e-8)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(specgram, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd4aa9",
   "metadata": {},
   "source": [
    "### 1. Signal extraction\n",
    "\n",
    "#### i. Selecting pixels corresponding to signal\n",
    "We will begin with selecting pixels of normalized spectrogram that are that are 3 times greater than the row and column median and set them all to 1 and the rest to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1336d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select segments containing audio and plot the spectrogram\n",
    "threshold = 3\n",
    "col_mask = specgram > threshold * np.median(specgram, axis=0) #elements of spectrogram greater than 3*median of column\n",
    "row_mask = specgram.T > threshold * np.median(specgram, axis=1) #elements of spectrogram greater than 3*median of row\n",
    "row_mask  = row_mask.T\n",
    "mask = col_mask & row_mask\n",
    "\n",
    "mask = mask.astype(int)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mask, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf4e40",
   "metadata": {},
   "source": [
    "#### ii. Binary erosion\n",
    "Let's apply a 4 by 4 binary erosion filter to the masked spectrogram to remove noise and visualize the output of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ac24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erosion\n",
    "audio_be_mask = binary_erosion(mask, np.ones((4, 4)))\n",
    "audio_be_mask\n",
    "audio_be_mask = audio_be_mask.astype(int)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(audio_be_mask, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc04eed",
   "metadata": {},
   "source": [
    "#### iii. Binary dilation\n",
    "Let's now apply a 4 by 4 binary dilation filter to the spectrogram obtained above to smoothen it visualize the output of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a6ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilation\n",
    "audio_bd_be_mask = binary_dilation(audio_be_mask, np.ones((2, 2)))\n",
    "audio_bd_be_mask = audio_bd_be_mask.astype(int)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(audio_bd_be_mask, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73c03c",
   "metadata": {},
   "source": [
    "#### iv. Indicator vector\n",
    "We will generate an indicator vector of the same length as the number of columns of the spectrogram. Each column of the spectrogram represent a window that the audio file was split into to perform short time fourier transform (STFT). The indicator vector is created by making its i-th element to 1 if there is at least one 1 in the i-th column and 0 otherwise. We then smoothen the vector by applying two 4 by 1 dilation filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34be5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col = np.max(audio_bd_be_mask, axis=0)\n",
    "bd_sel_col = binary_dilation(selected_col[:, None], np.ones((4, 1)))\n",
    "bd2_sel_col = binary_dilation(bd_sel_col, np.ones((4, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569ab3a7",
   "metadata": {},
   "source": [
    "#### v. Signal mask\n",
    "The indicator vector obtained above is scaled to the length of the audio file and used to extract parts of the audio that correspond to a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42981dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate to audio samples\n",
    "selection_mtx = np.ones((specgram.shape[1], hop_len)) * bd2_sel_col\n",
    "\n",
    "audio_indx = selection_mtx.flatten().astype(bool)\n",
    "selection_mtx.shape\n",
    "\n",
    "audio_indx = selection_mtx.flatten().astype(bool)\n",
    "\n",
    "signal = y[audio_indx[:len(y)]]\n",
    "IPython.display.Audio(signal, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed3cbe",
   "metadata": {},
   "source": [
    "#### vi. Visualizing the extracted signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d615543",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_audio = np.abs(librosa.stft(signal, \n",
    "                        n_fft=nfft, \n",
    "                        hop_length=hop_len))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S_audio, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811e1ef",
   "metadata": {},
   "source": [
    "### 2. Noise extraction\n",
    "In the sections that follow, we will repeat the steps followed in signal extraction, however, we will set the threshold for selecting pixels at 2.5 time greater than row and column median.\n",
    "#### i. Selecting pixels 2.5 time greater than row and column median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2.5\n",
    "col_mask = specgram > threshold * np.median(specgram, axis=0) #elements of spectrogram greater the 3*median of column\n",
    "row_mask = specgram.T > threshold * np.median(specgram, axis=1) #elements of spectrogram greater the 3*median of row\n",
    "row_mask  = row_mask.T\n",
    "mask = col_mask & row_mask\n",
    "\n",
    "mask = mask.astype(int)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mask, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20324337",
   "metadata": {},
   "source": [
    "#### ii. Binary erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erosion\n",
    "noise_be_mask = binary_erosion(mask, np.ones((2, 2)))\n",
    "noise_be_mask\n",
    "noise_be_mask = noise_be_mask.astype(int)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(noise_be_mask, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae42224",
   "metadata": {},
   "source": [
    "#### iii. Binary dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilation\n",
    "noise_bd_be_mask = binary_dilation(noise_be_mask, np.ones((2, 2)))\n",
    "noise_bd_be_mask = noise_bd_be_mask.astype(int)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(noise_bd_be_mask, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c94e2",
   "metadata": {},
   "source": [
    "#### iv. Indicator vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a566eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col = np.max(audio_bd_be_mask, axis=0)\n",
    "bd_sel_col = binary_dilation(selected_col[:, None], np.ones((4, 1)))\n",
    "bd2_sel_col = binary_dilation(bd_sel_col, np.ones((4, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891b387",
   "metadata": {},
   "source": [
    "#### v. Indicator mask\n",
    "The indicator vector obtained above is scaled to the length of the audio file, inverted and used to extract parts of the audio that correspond to noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate to audio samples\n",
    "selection_mtx = np.ones((specgram.shape[1], hop_len)) * bd2_sel_col\n",
    "\n",
    "audio_indx = selection_mtx.flatten().astype(bool)\n",
    "selection_mtx.shape\n",
    "\n",
    "audio_indx = selection_mtx.flatten().astype(bool)\n",
    "\n",
    "audio_indx = ~audio_indx\n",
    "\n",
    "noise = y[audio_indx[:len(y)]]\n",
    "IPython.display.Audio(noise, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_noise = np.abs(librosa.stft(noise, \n",
    "                        n_fft=nfft, \n",
    "                        hop_length=hop_len))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S_noise, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63583b6b",
   "metadata": {},
   "source": [
    "Let's now repeat the above steps on the entire files that we downloaded and save the extracted signal and noise parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions get the indices corresponding to audio and noise in a file\n",
    "\n",
    "def compute_audio_mask(norm_specgram, hop_len, category='audio'):\n",
    "    \"\"\" Compute the section of signal corresponding to audio or noise\n",
    "    This follows the approach described in\n",
    "    Sprengel, E., Jaggi, M., Kilcher, Y., & Hofmann, T. (2016).\n",
    "    Audio based bird species identification using deep learning techniques\n",
    "    Args:\n",
    "        norm_specgram: input spectrogram with values in range [0,1]\n",
    "        hop_len: hop length used to generate the spectrogram\n",
    "        category: whether 'audio' or 'noise'\n",
    "    Returns:\n",
    "        mask: the mask of samples belonging to 'category'\n",
    "    Raises: ValueError if the category is not known\n",
    "    \"\"\"\n",
    "\n",
    "    if category == 'audio':\n",
    "        threshold = 3\n",
    "    elif category == 'noise':\n",
    "        threshold = 2.5\n",
    "    else:\n",
    "        raise ValueError('Unknown category')\n",
    "\n",
    "    col_mask = norm_specgram > threshold * np.median(norm_specgram, axis=0)\n",
    "    row_mask = norm_specgram.T > threshold * np.median(norm_specgram, axis=1)\n",
    "    row_mask  = row_mask.T\n",
    "    mask = col_mask & row_mask\n",
    "\n",
    "    # erosion\n",
    "    be_mask = binary_erosion(mask, np.ones((4, 4)))\n",
    "\n",
    "    # dilation\n",
    "    bd_be_mask = binary_dilation(be_mask, np.ones((4, 4)))\n",
    "\n",
    "    bd_be_mask = bd_be_mask.astype(int)\n",
    "    selected_col = np.max(bd_be_mask, axis=0)\n",
    "    bd_sel_col = binary_dilation(selected_col[:, None], np.ones((4, 1)))\n",
    "    bd2_sel_col = binary_dilation(bd_sel_col, np.ones((4, 1)))\n",
    "\n",
    "\n",
    "    # translate to audio samples\n",
    "    selection_mtx = np.ones((norm_specgram.shape[1], hop_len)) * selected_col[:, None]\n",
    "\n",
    "    audio_indx = selection_mtx.flatten().astype(bool)\n",
    "\n",
    "    if category == 'audio':\n",
    "        return audio_indx\n",
    "    else:\n",
    "        return ~audio_indx\n",
    "\n",
    "\n",
    "\n",
    "def get_audio_noise(audio_array, nfft, hop_len):\n",
    "    \"\"\" Get both the signal and noise\n",
    "    Args:\n",
    "        audio_array: an array of audio\n",
    "        nfft: FFT length\n",
    "        hop_len: hop length\n",
    "    Returns:\n",
    "        signal and noise\n",
    "    \"\"\"\n",
    "\n",
    "    specgram = np.abs(librosa.stft(audio_array, n_fft=nfft, hop_length=hop_len))\n",
    "    specgram_norm = specgram / (specgram.max() + 1e-8)\n",
    "\n",
    "    audio_indx = compute_audio_mask(specgram_norm, hop_len)[:len(audio_array)]\n",
    "    noise_indx = compute_audio_mask(specgram_norm, hop_len, 'noise')[:len(audio_array)]\n",
    "\n",
    "\n",
    "    return audio_array[audio_indx], audio_array[noise_indx]\n",
    "\n",
    "\n",
    "def audio_noise_save(rec_dir, sr, nfft, hop_len, audio_dir, noise_dir):\n",
    "    \"\"\" Save separated audio and noise parts\n",
    "    Args:\n",
    "        audio_array: an array of audio\n",
    "        nfft: FFT length\n",
    "        hop_len: hop length\n",
    "        audio_dir-path to save audio segment\n",
    "        noise_dir-path to save noise segment\n",
    "        rec_dir-recordings' directory\n",
    "        sr-sampling rate\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    birds_dir = next(os.walk(rec_dir))[1]\n",
    "    for species in birds_dir:\n",
    "        recs = os.listdir(os.path.join(rec_dir, species))\n",
    "        path = os.path.join(audio_dir, species) #path to store recording of a given species\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        for file in tqdm(recs):\n",
    "            try:\n",
    "                y,_ = librosa.load(os.path.join(rec_dir, species, file), sr=sr)\n",
    "                audio, noise = get_audio_noise(y, nfft, hop_len)\n",
    "            except Exception as e:\n",
    "                return\n",
    "            \n",
    "            sf.write(os.path.join(path,\n",
    "                          file.replace('mp3', 'wav')),\n",
    "             audio,\n",
    "             sr)\n",
    "            sf.write(os.path.join(noise_dir,\n",
    "                                  file.replace('mp3', 'wav')),\n",
    "                     noise,\n",
    "                     sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_noise_save('./xeno-canto',\n",
    "                 sr,\n",
    "                 nfft,\n",
    "                 hop_len,\n",
    "                 './noiseless-xeno-canto',\n",
    "                 './noise')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
