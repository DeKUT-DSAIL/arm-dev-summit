{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d83c2d",
   "metadata": {},
   "source": [
    "# Features Generation\n",
    "In this notebook, we will compute the melspectrograms of the audio files. Melspectrograms are obtained by converting the frequency axis of a spectrogram into a mel scale. Spectrograms are computed by passing an audio through short-time Fourier transform (STFT), in our case using a Hamming window of size 1024 with 75% overlap. Audio files that are shorter than the threshold length are padded with noise to ensure they are at least threshold length long. The computed spectrograms are then converted to melspectrograms using 40 mel filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26190167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b043f4d",
   "metadata": {},
   "source": [
    "## Load the parameters required to compute the spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters from configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('parameters.ini')\n",
    "\n",
    "win_len_ms = int(config['audio']['win_len_ms'])\n",
    "overlap = float(config['audio']['overlap'])\n",
    "sampling_rate = int(config['audio']['sampling_rate'])\n",
    "\n",
    "# Derive audio processing values\n",
    "win_len = int((win_len_ms * sampling_rate) / 1000)\n",
    "hop_len = int(win_len * (1 - overlap))\n",
    "nfft = int(2 ** np.ceil(np.log2(win_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab9cc5",
   "metadata": {},
   "source": [
    "## Audio padding\n",
    "For our classification models, we need fixed size inputs. However, before and after signal and noise separation, some files have shorter lengths than the required threshold lenghth. To ensure these files are of at least threshold-length long, we will pad them with noise. Padding a signal with noise helps in developing the model by exposing it to the noise it will encounter in the field. \n",
    "\n",
    "Let's load a signal file and plot its spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91147a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, _ = librosa.load('./sample_data/signal.wav', sr=sampling_rate)\n",
    "\n",
    "specgram = np.abs(librosa.stft(signal, \n",
    "                        n_fft=nfft, \n",
    "                        hop_length=hop_len))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(specgram, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568982cc",
   "metadata": {},
   "source": [
    "Now, let's pad it with noise to ensure it is at least 3 seconds long and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 3\n",
    "\n",
    "if (len(signal) / sampling_rate) < duration:\n",
    "    noise, _ = librosa.load('./sample_data/noise.wav', sr=sampling_rate)\n",
    "    while (len(signal) / sampling_rate) < duration:\n",
    "        signal = np.concatenate((signal,noise))\n",
    "        \n",
    "signal = signal[:int(duration * sampling_rate) + 1]\n",
    "\n",
    "specgram = np.abs(librosa.stft(signal, \n",
    "                        n_fft=nfft, \n",
    "                        hop_length=hop_len))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(specgram, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=hop_len,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a4673",
   "metadata": {},
   "source": [
    "Now let's perform the above steps to the signal files we obtained from separating signals and noise from the downloaded audio files. We will then compute the melspectrograms of the files and store them as numpy array files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_audio(signal, duration, sampling_rate, noise_dir):\n",
    "    \"\"\" Pad signal if necessary to ensure it is at least duration seconds long\n",
    "    Args:\n",
    "        signal: the signal to be padded\n",
    "        duration: the minimum duration\n",
    "        sampling_rate: the sampling rate\n",
    "        noise_dir: the noise directory\n",
    "    Returns:\n",
    "        the original signal or a signal padded to duration\n",
    "    \"\"\"\n",
    "    \n",
    "    audio_duration = len(signal) / sampling_rate\n",
    "    noise_files = os.listdir(noise_dir)\n",
    "    if audio_duration >= duration:\n",
    "        return signal\n",
    "    else:\n",
    "        #print(len(signal) / sampling_rate)\n",
    "        filename = random.choice(noise_files)\n",
    "        noise_signal, _ = librosa.load(os.path.join(noise_dir, filename),\n",
    "                                      sr=sampling_rate)\n",
    "        while (len(signal) / sampling_rate) < duration:\n",
    "            signal = np.concatenate((signal, noise_signal))\n",
    "        #print(len(signal) / sampling_rate)  \n",
    "        return signal[:int(duration * sampling_rate) + 1]\n",
    "    \n",
    "    \n",
    "def features_extraction(audio_dir,\n",
    "                         name,\n",
    "                         species,\n",
    "                         file,\n",
    "                         noise_dir,\n",
    "                         sampling_rate,\n",
    "                         duration,\n",
    "                         nfft,\n",
    "                         win_length,\n",
    "                         hop_length,\n",
    "                         num_mels=40,\n",
    "                         melspectrogram_dir=None):\n",
    "    \n",
    "    \"\"\"Compute features for all files in the list\n",
    "    Args:\n",
    "        audio_dir: directory containig audio\n",
    "        name: name to save the melspectrogram with\n",
    "        species: name of the subdirectory containing a given species' recordings\n",
    "        file: name of the recording\n",
    "        noise_dir: directory with noise samples for padding\n",
    "        sampling_rate: audio sampling rate\n",
    "        duration: minimum duration of files\n",
    "        nfft: FFT length\n",
    "        win_length: window length\n",
    "        hop_length: overlap between adjascent frames\n",
    "        num_mel: number of melspectrogram channels\n",
    "        melspectrogram_dir: directory to save spectrograms\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        y, _ = librosa.load(os.path.join(audio_dir, species, file),\n",
    "                                sr=sampling_rate)\n",
    "        signal = pad_audio(y, duration, sampling_rate, noise_dir)\n",
    "                \n",
    "        file_features = librosa.feature.melspectrogram(signal,\n",
    "                                                        sr=sampling_rate,\n",
    "                                                        n_fft=nfft,\n",
    "                                                        hop_length=hop_length,\n",
    "                                                        win_length=win_length,\n",
    "                                                        window='hamming',\n",
    "                                                        n_mels=num_mels)\n",
    "        \n",
    "        if not os.path.exists(melspectrogram_dir):\n",
    "            os.makedirs(melspectrogram_dir)\n",
    "        np.save(melspectrogram_dir + '/' + name , file_features)\n",
    "    except (FileNotFoundError, EOFError) as e:\n",
    "        print('{} not found'.format(file))\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd64af",
   "metadata": {},
   "source": [
    "Saving melspectrograms and annotation csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6682c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_dir = './noiseless-xenocanto'\n",
    "recordings = next(os.walk(audio_dir))[1]\n",
    "noise_dir = './noise'\n",
    "duration = 3\n",
    "\n",
    "labels_list = []\n",
    "field_names = ['no.', 'name', 'label']\n",
    "no = 0\n",
    "\n",
    "for species in recordings:\n",
    "        files = tqdm(os.listdir(os.path.join(audio_dir, species)))\n",
    "        for indx, file in enumerate (files):\n",
    "            labels_dict = {}\n",
    "            name = species + str(indx) + '.npy'\n",
    "            labels_dict.update({'no.':no, 'name':name, 'label':species})\n",
    "            labels_list.append(labels_dict)\n",
    "            files.set_description(\"Processing %s files\" % species)\n",
    "            features_extraction(audio_dir,\n",
    "                                 name,\n",
    "                                 species,\n",
    "                                 file,\n",
    "                                 noise_dir,\n",
    "                                 sampling_rate,\n",
    "                                 duration,\n",
    "                                 nfft,\n",
    "                                 win_len,\n",
    "                                 hop_len,\n",
    "                                 num_mels=40,\n",
    "                                 melspectrogram_dir='./melspectrograms')\n",
    "            no += 1\n",
    "            \n",
    "with open('labels.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(labels_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
